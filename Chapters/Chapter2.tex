\chapter{Literature Survey}

Non-stop supply of nutritious food production for the ever increasing population as well because the challenges of global market have factored in the need for newer efficient farming systems. Precision Farming is a scientific approach to enhance the agricultural management by adoption of data to spot, analyse and manage the spatial and temporal viability of science parameters. 


Most conservation researchers and practitioners currently rely on satellite-based remote sensing for mapping and monitoring land use change~\cite{broich2011time}. However, remote sensing technology might not be accessible for many developing-country researchers due to financial constraints. Although certain low-resolution satellite images are freely available (e.g., Landsat~\cite{LandsatS1:online} and MODIS ~\cite{LandsatS40:online}), other sub-meter resolution images can be prohibitively costly (e.g., QuickBird ~\cite{LandsatS4:online}, IKONOS ~\cite{geoeyeco87:online}). Yet, such high-resolution data are often critical for accurately detecting and tracking land use change at the landscape scale.

Furthermore, much of the humid tropics is often obscured from remote sensing satellites due to a persistent cloud cover~\cite{hansen2008method}. As such, cloud-free satellite images for a specific time period and location are often not readily available. Researchers typically have to search from a time series of images to obtain the cloud-free data they require, thus rendering any real-time monitoring of land-use change practically impossible. 

\section{Drone Development and operation}
The autopilot system of such precision farming drones is based on the ‘ArduPilot Mega’ (APM), which has been developed by an online community of ``diydrones''~\cite{diydrone38:online}. The APM includes a computer processor, geographic positioning system (GPS), data logger, pressure and temperature sensor, airspeed sensor, triple-axis gyro, and accelerometer. By combining the APM with an open-source mission planner software (APM Planner), most remote control model airplanes could be con verted to an autonomous drone~\cite{ardupilo77:online}.

Previous versions of APM 2.6 had only the onboard compass which resulted in very large offsets during the flight tests and even in calibration phase. Due to off-board compass amalgamated with GPS, accuracy of the autonomous flight is considerably increased. Also, proper tuning was not available easily in the previous versions.

Our choice of flight controller is also based on which type of rotor we would be using.  As we are using Multi Rotor and not a fixed wing machine, APM 2.5 doesn't seem to catch up with the applicative need of our mission of multi-rotor(hex-copter). If we are flying a fixed-wing rotor (plane) then APM 2.5 is the better choice as its slightly cheaper and due to the space we can mount the APM away from magnetic interference (motors/ESC). Also the higher speed Mediatek module is better suited to faster moving vehicles. While if we are flying Multi-rotor (hex-copter), then its best to go with the APM 2.6 as the GPS module is better suited to slower moving platforms, and the external compass allows us to mount it away from interferance from all the ESC's we have on Multicopters~\cite{APM25orA25:online}.



\section{Spectral signature of vegetation}

A plant leaf does not absorb all wavelengths uniformly since it consists of biochemical and chemical substances with different absorption peaks. It is documented that various pigments - such as chlorophyll-a and chlorophyll-b,  anthocyanin, $\alpha$ and $\beta$-carotenoids, lutein, violaxanthin - the physical structure of leaves and their water content are the main factors determining the spectral signature ~\cite{zwiggelaar1998review,campbell2011introduction}.

An interesting point is that these components change during the season, depending on the phenophase, species, and nutrient conditions. The spectral signatures of leaves can therefore be utilized to monitor various plant conditions, such as nutrient and water deficiency, and to identify crop types and weeds. 

At the canopy level, the absorption peaks of the chemical substances generally become unclear, since reflectance from canopy is strongly influenced by leaf size, plant density, number of layers, orientation of leaves, and other environmental factors such as soil reflectance and light angle~\cite{campbell2011introduction}. However, some of the biochemical properties are still detectable from the canopy reflectance. Indeed, the canopy reflectance spectrum has been used to identify crop types~\cite{serpico1996experimental} and weeds~\cite{goel2002use,goel2003potential,lamb1999evaluating,lass1996detection}, to detect water and nutrient stress~\cite{goel2002use,goel2003potential,lelong1998hyperspectral,shibayama1993canopy}, and to estimate crop phenology~\cite{railyan1993red,boissard1993reflectance}, leaf area index~\cite{aparicio2002relationship,rastogi2000estimation,shibayama1989seasonal} and plant biomass~\cite{serrano2000remote}.

\section{Image Stitching}
In the stitching method mentioned in~\cite{chen2014image} first of all feature extraction takes place through harris corner detection and feature is matched by finding the normalized cross correlation between them. After that ransac is used to remove the outliers and to eliminate the error matching. Another method overcome the limitation of SIFT i.e. sensitive to non linear illumination changes~\cite{yang2014image}. In this method initially feature points are extracted by SYFM(a local symmetry based descriptor)and SIFT(gradient based descriptor). Then SIFT descriptor and local symmetry are combined to characterize those feature point. After that feature matching is carried out by ``randomized kd trees'' and transform parameters are calculated by correct inner points after ransac was used to eliminate wrong matches. In the case of drone image stitching we must understand the fact that the images have GPS points encoded in them , which can be used to stitch the images . This method gives better result than other methods because apart from the features which we extract from images we can use the GPS points to arrange and stitch the images characterize those feature point. After that feature matching is carried out by ``randomized kd trees'' and transform parameters are calculated by correct inner points after ransac was used to eliminate wrong matches.

\section{Vegetation Indices and Machine Learning}
Over the years, a number of vegetation indices (VIs) have been developed by combining two or more wavebands in the hyperspectral images in ratios and/or differences, to highlight various crop conditions. However, one of the problems in applying VIs to crop yield estimation is the difficulty in choosing the most appropriate vegetation index in a specific situation~\cite{barrett1999fractional}. In fact, various environmental factors, such as background effects and crop canopy conditions, have been shown to be potential sources of noise, which affect the spectral reflectance in canopy level~\cite{aparicio2000spatial}.

Artificial intelligence and especially machine learning have contributed to the creation of control systems in agriculture. There are a lot of machine learning algorithms like Support Vector Machines(SVM), Simple Multivariate Linear Regressions(SMLR), Decision Trees(DT), Neural Networks(NN), etc. available that can be utilized for recognizing intricate patterns in data.

Applying machine learning models in addition to the VI based methods have resulted in great results as shown by Farid Melgani and Lorenzo Bruzzone in ~\cite{melgani2004classification}.


\section{Deep Learning for Image-Based Plant Disease Detection}
Crop diseases are a major threat to food security, but their rapid identification remains difficult in many parts of the world due to the lack of the necessary infrastructure.

Modern technologies have given human society the ability to produce enough food to meet the demand of more than 7 billion people. However, food security remains threatened by a number of factors including climate change[1], the decline in pollinators~\cite{bay2008speeded}, plant diseases~\cite{dalal2005histograms}, and others. Plant diseases are not only a threat to food security at the global scale, but can also have disastrous consequences for smallholder farmers whose livelihoods depend on healthy crops. In the developing world, more than 80 percent of the agricultural production is generated by smallholder farmers~\cite{deng2009imagenet}, and reports of yield loss of more than 50\% due to pests and diseases are common~\cite{ehler2006integrated}. Furthermore, the largest fraction of hungry people (50\%) live in smallholder farming households~\cite{everingham2010pascal}, making smallholder farmers a group that’s particularly vulnerable to pathogen-derived disruptions in food supply.

Various efforts have been developed to prevent crop loss due to diseases. Historical approaches of widespread application of pesticides have in the past decade increasingly been supplemented by integrated pest management (IPM) approaches~\cite{garcia2013comparison}. Independent of the approach, identifying a disease correctly when it first appears is a crucial step for efficient disease management. Historically, disease identification has been supported by agricultural extension organizations or other institutions such as local plant clinics. In more recent times, such efforts have additionally been supported by providing information for disease diagnosis online, leveraging the increasing internet penetration worldwide. Even more recently, tools based on mobile phones have proliferated, taking advantage of the historically unparalleled rapid uptake of mobile phone technology in all parts of the world~\cite{bold2012mobile}. 


Smartphones in particular offer very novel approaches to help identify diseases because of their tremendous computing power, high-resolution displays, and extensive built-in sets of accessories such as advanced HD cameras. It is widely estimated that there will be between 5 and 6 billion smartphones on the globe by 2020. At the end of 2015, already 69\% of the world’s population had access to mobile broadband coverage, and mobile broadband penetration reached 47\% in 2015, a 12-fold increase since 2007~\cite{bold2012mobile}. The combined factors of widespread smartphone penetration, HD cameras, and high performance processors in mobile devices lead to a situation where disease diagnosis based on automated image recognition, if technically feasible, can be made available at an unprecedented scale. 

Computer vision, and object recognition in particular, has made tremendous advances in the past few years. The PASCAL VOC Challenge~\cite{he2016deep}, and more recently the Large Scale Visual Recognition Challenge (ILSVRC)~\cite{hernandez2014integrating} based on the ImageNet dataset~\cite{huang2007application} have been widely used as benchmarks for numerous visualization-related problems in computer vision, including object classification. In 2012, a large, deep convolutional neural network achieved a top-5 error of 16.4\% for the classification of images into 1,000 possible categories~\cite{hughes2015open}. In the following three years, various advances in deep convolutional neural networks lowered the error rate to 3.57\% ~\cite{hughes2015open,facts2015figures,jia2014caffe,krizhevsky2012imagenet,lecun1989backpropagation}.


\section{Summary}

In the literary review, we have enlisted the various techniques that are currently being used in precision farming using Unmanned Aerial Vehicle(UAV). We based our prototype drone on a popular model airplane (DJI Model). This hex-copter is relatively inexpensive, lightweight, and has ample room within its fuselage for installing the APM and an onboard camera. The Hex-copter is also be equipped with a video camera. We used a GoPro HD Hero camera housed within a protective shockproof casing~\cite{NewTab52:online}. This camera was attached to the belly of the hex-copter and pointed at around 45 degrees forwards and downwards. Previously VI based methods have been used for image analysis. But these methods seem to be greatly affected by environmental noise. Machine learning has also shown good results in this field and therefore, a combination of VI based method and machine learning  is used for the analysis of the farm. The role of GIS in different agricultural scenarios has also been discussed. The use of deep learning for crop disease prediction is also employed for providing bettter prescription to the farmers. The model and approach for an agricultural system can be easily noted by analysis of past work. Thus such literature allows for an easy yet fast approach towards a complete prototype.